\documentclass[9pt]{article}
\usepackage{amsthm,amssymb,graphicx,graphicx,multirow,amsmath,cite}
\usepackage[usenames,dvipsnames]{color}
\usepackage{epstopdf}
\usepackage{etoolbox}

% coloring code snippets
\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}

\include{notation}
\oddsidemargin=0.15in
\evensidemargin=0.15in
\topmargin=-.5in
\textheight=9in
\textwidth=6.25in
%\bootrue{Advanced}

\newtheorem{lemma}{Lemma}{}
  \newtheorem{thm}{Theorem}
  \newtheorem{theorem}{Theorem}
  \newtheorem{prop}{Proposition}
  \newtheorem{cor}[thm]{Corollary}
  \newtheorem{defi}[thm]{Definition}
  \newtheorem{definition}[thm]{Definition}
  
  %% USE THESE IN YOUR TEX CODE.
\def\E{\mathbb{E}} % For Expectation
\def\P{\mathbb{P}} % for probabiltiy
\def\EE{\mathbb{E}^{!o}} % For Palm expectation
\def\ie{{\em i.e.}} 
\def\eg{{\em e.g.}}
\def\V{\operatorname{Var}}
\def\L{\mathcal{L}} % For Laplace transform
\def\i{\mathbf{1}} % Indicator random variable
\def\l{\ell}% For path loss moel

\begin{document}
\lstset{language=Matlab,%
	basicstyle=\footnotesize,  
    breaklines=true,%
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},%
    morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},%
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},%
    showstringspaces=false,%without this there will be a symbol in the places where there is a space
    numbers=left,%
    numberstyle={\tiny \color{black}},% size of the numbers
    numbersep=9pt, % this defines how far the numbers are from the text
    emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
    %emph=[2]{word1,word2}, emphstyle=[2]{style},    
}
 
\input{preamble.tex}
\labreport{3}{10/18/2015}{Community Detection in Networks}{Prasanth Prahladan}{100817764}

We model a network comprising of n agents by using a $n \times n$ symmetric Adjacency Matrix, $\mathbf{A}$, defined by
\begin{align}
A = [a_{ij}] &= \bigg\lbrace \begin{array}{cc}
1 & \text{if i,j are linked/friends}\\
0 & \text{otherwise}
\end{array} \label{eq:AdjacencyMatrix}
\end{align}

Given a random realization A of a \emph{Planted Partition G(n,p,q)}, the goal is to identify the two communities. Our ability to detect the partitions will decrease as $(p-q) \to 0$. Any $A \in G(n,p,q)$ can be generated by the following model, 
\begin{align}
A &= TBT^T \label{eq:RandomAdjacencyMatrix}\\
B &=  \begin{bmatrix}
B_{1,1}(p) & \cdots & B_{1,n/2}(p) &B_{1,n/2 + 1}(q) & \cdots & B_{1,n}(q)\\
\vdots& & \vdots& \vdots & &\vdots\\
B_{n/2,1}(p) & \cdots & B_{n/2,n/2}(p) &B_{n/2,n/2 + 1}(q) & \cdots & B_{n/2,n}(q)\\
B_{n/2+1,1}(q) & \cdots & B_{n/2+1,n/2}(q) &B_{n/2+1,n/2 + 1}(p) & \cdots & B_{n/2+1,n}(p)\\
\vdots& & \vdots& \vdots & &\vdots\\
B_{n,1}(q) & \cdots & B_{n,n/2}(q) &B_{n,n/2 + 1}(p) & \cdots & B_{n,n}(p)\\
\end{bmatrix} \label{eq:OrderedClusterAdjacencyMatrix}
\end{align}
where, $B_{i,j}(p)$ are Bernoulli random variables and T is a Permutation Matrix. 

For the analysis below, we make the following assumptions: we assume that we have an oracle that gives us access to T. Our algorithm will not require this assumption, though this assumption helps in the analysis. (wlog. we assume $T = I(n)$, the Identity matrix).

Our approach relies on the computation of the second dominant eigenvector of A.

\section{The eigenvectors of the expected value of A}

\textbf{Q1.} Prove that the expected adjacency matrix, $M = \E{[A]}$, has the form
\begin{align}
M &= \begin{bmatrix}
p & \cdots &p&q&\cdots&q\\
\vdots &  &\vdots &\vdots & &\vdots\\
p & \cdots &p&q&\cdots&q\\
q & \cdots &q&p&\cdots&p\\
\vdots &  &\vdots &\vdots & &\vdots\\
q & \cdots &q&p&\cdots&p\\
\end{bmatrix}
\end{align}\\
We assume that $T = I(n)$, and since $M = \E{[A]} \implies M = [m_{i,j}] = [\E{a_{i,j}}]$, where each $a_{i,j}$ is a Bernoulli random-variable described in \eqref{eq:OrderedClusterAdjacencyMatrix}
\begin{align}
m_{i,j} = \E{[a_{i,j}]} = \Bigg\lbrace \begin{array}{cc}
1 \times p + 0 \times (1-p) & 1\leq i,j \leq n/2 \text{ and } n/2+1 \leq i,j \leq n\\
1 \times q + 0 \times (1-q) & 1 \leq i \leq n/2 \text{ and } n/2+1 \leq j \leq n \text{ and otherwise.}
\end{array}
\end{align}
Thus, we prove M has the above structure.\\


\textbf{Q2.}The degree matrix, is defined as the diagonal matrix with entries $d_i = \sum_{j=1}^n A_{ij}$. Derive the expression for the Expected Degree Matrix $\E{[D]}$.\\
From \eqref{eq:OrderedClusterAdjacencyMatrix} with $T = I(n)$, we have $A = B$. Further, by definition of the Degree Matrix we have each $d_i$ to be the sum along a row of the adjacency matrix
\begin{align}
d_i = \sum_{j=1}^n A_{ij} = \frac{n}{2} p + \frac{n}{2} q = \frac{n}{2}(p+q).
\end{align}


\textbf{Q3.}Prove that the vector $w_1 = \frac{1}{\sqrt{n}}\i$ is an eigenvector of M. Determine the corresponding eigenvalue $\mu_1$.\\
We observe the following for $v_1 = Mw_1 = M\frac{1}{\sqrt{n}}\i$
\begin{align}
Mw_1 &= \begin{bmatrix}
p & \cdots &p&q&\cdots&q\\
\vdots &  &\vdots &\vdots & &\vdots\\
p & \cdots &p&q&\cdots&q\\
q & \cdots &q&p&\cdots&p\\
\vdots &  &\vdots &\vdots & &\vdots\\
q & \cdots &q&p&\cdots&p\\
\end{bmatrix}\frac{1}{\sqrt{n}}\i \\
v_{1,i} &= \frac{1}{\sqrt{n}}\sum_{j=1}^n [ p \cdots q ]\i \notag\\
&= \frac{1}{\sqrt{n}} \frac{n}{2}(p+q) \notag\\
v_1 &=  \frac{n}{2}(p+q) ( \frac{1}{\sqrt{n}} \i) = \frac{n}{2}(p+q)w_1 = Mw_1.
\end{align}
Therefore, $w_1$ is an eigenvector of M, with eigenvalue $\mu_1 = \frac{n(p+q)}{2}$.\\

\textbf{Q4.}Prove that the vector $w_2 $ is an eigenvector of M, and determine the corresponding eigenvalue, when 
\begin{align}
w_2(i) = \frac{1}{\sqrt{n}}\bigg\lbrace \begin{array}{cc}
1 & \text{if } 1 \leq i \leq n/2 \\
-1 & \text{otherwise} 
\end{array} 
\end{align}	

We observe the following for $v_2 = Mw_2 $
\begin{align}
v_{2,i} &= \sum_{j=1}^n [ p \cdots q ] w_{2,i}\\
&= \frac{1}{\sqrt{n}} \frac{n}{2}(p-q) \notag\\
v_2 &= \frac{n}{2}(p-q)w_2=  Mw_2.
\end{align}
Therefore, $w_2$ is an eigenvector of M, with eigenvalue $\mu_2 = \frac{n(p-q)}{2}$.



\textbf{Q5.} Sketch the graph of the eigenvectors of M, $w_3$ and $w_4$, where
\begin{align}
w_3(i) &= \frac{1}{\sqrt{n}} \Bigg\lbrace \begin{array}{cc}
1 & \text{if } 1 \leq i \leq n/4 \\
-1 & \text{if } n/4 < i \leq 3n/4 \\
1 & \text{if } 3n/4 < i < n 
\end{array}\\
w_4(i) &= \frac{1}{\sqrt{n}} \Bigg\lbrace \begin{array}{cc}
1 & \text{if }1 \leq i \leq n/4 \\
-1 & \text{if }n/4 < i \leq 2n/4 \\
1 & \text{if }2n/4 < i \leq 3n/4 \\
-1 & \text{if }3n/4 < i < n .
\end{array}
\end{align}


\textbf{Q6. }Prove that $w_3$ and $w_4$ are in the Null Space of the matrix $\E{[A]}$.\\
By the structures of M, $w_3, w_4$ we observe that for $v_3 = Mw_3$ and $v_4 = Mw_4$
\begin{align*}
v_{3,1} = \frac{n}{4} p + \frac{n}{4} (-p) + \frac{n}{4} (-q) + \frac{n}{4} q = 0\\
v_{4,1} = \frac{n}{4} p + \frac{n}{4} (-p) + \frac{n}{4} q + \frac{n}{4} (-q) = 0\\
\end{align*}
Similarly, we can prove $v_{3,i} = 0 , v_{4,i} = 0 \forall i \leq n$.
Therefore, $Mw_3 = 0\i = Mw_4$. Thus, by definition of Null Space, we have $\{w_3,w_4\} \in NullSpace(M)$.\\

\textbf{Q7. } Prove that \begin{align}
M = \mu_1 w_1 w_1^T + \mu_2 w_2 w_2^T
\end{align}
Considering the RHS and solving, we obtain
\begin{align*}
RHS = \mu_1 w_1 w_1^T + \mu_2 w_2 w_2^T &= (\frac{n(p+q)}{2})  \frac{1}{n} \i \i^T  + (\frac{n(p-q)}{2})  w_2 w_2^T\\
&= \begin{bmatrix}
[\frac{p+q}{2} + \frac{p-q}{2}] & [\frac{p+q}{2} - \frac{p-q}{2}]\\
[\frac{p+q}{2} - \frac{p-q}{2}] & [\frac{p+q}{2} + \frac{p-q}{2}]\\
\end{bmatrix} \\
&= \begin{bmatrix}
[p] & [q]\\
[q] & [p]\\
\end{bmatrix}  = M = LHS\\
\end{align*}
where $[\cdots]$ represents a block matrix of size $n/2 \times n/2$. Thus, we have proved the above result.\\


\textbf{Q8. } Describe a simple algorithm to recover two communities using the eigenvectors of M.
Given the eigenvectors $\{w_1, w_2, w_3, w_4\}$ of M, we determine from the above results that
\begin{align*}
M = \mu_1 w_1 w_1^T + \mu_2 w_2 w_2^T \\
A = \gamma_1 w_1 w_1^T + \gamma_2 w_2 w_2^T + \gamma_3 w_3 w_3^T + \gamma_4 w_4 w_4^T\\
\end{align*}
Using the components of $w_2$, all the indices corresponding to positive entries correspond to one component and the negative entries correspond to another component. 

\textbf{Q9. } Prove that $\E{[X]}=0$, where the expectation is computed over all possible realizations of the matrix B, with $A = M + X$ and X is the symmetric random matrix 
\begin{align}
x_{i,j} &= \Bigg\lbrace \begin{array}{cc}
&\text{if } 1\leq i\leq j\leq n/2 \text{ or } n/2 < i\leq j \leq n\\
(1-p) & \text{w.p. } p\\
-p & \text{w.p. } (1-p)
\end{array}\\ \notag\\
x_{i,j} &= \Bigg\lbrace \begin{array}{cc}
&\text{if } 1 \leq i\leq n/2 \text{ and } n/2 < j \leq n\\
(1-q) & \text{w.p. } q\\
-q & \text{w.p. } (1-q)
\end{array}
\end{align}\\

From the definition of $X = [x_{i,j}]$ above, we obtain $\E{[X]} = [\E{[x_ij]}]$ as
\begin{align*}
\E{[x_{i,j}]} &= \Bigg\lbrace \begin{array}{cc}
(1-p) \times p + (-p) \times (1-p) & \text{if } 1\leq i\leq j\leq n/2 \text{ or } n/2 < i\leq j \leq n\\
(1-q) \times q + (-q) \times (1-q) & \text{if } 1 \leq i\leq n/2 \text{ and } n/2 < j \leq n\\
\end{array}\\
\E{[x_{i,j}]} &= 0.
\end{align*}
Therefore, we obtain $\E{[X]} = 0 \i \i^T$.

\section{Separating the dominant eigenvalues from the bulk}

X is a symmetric random matrix with independent entries that have mean zero. One can show that the empirical spectral distribution converges towards a slightly modified form of the Wigner semi-circle law, given by
\begin{align}
\frac{1}{\pi(p + q)} \sqrt{2n(p+q) - \lambda^2} \label{eq:ESD}
\end{align}
The dominant eigenvalues of A can be found from the decompositions of A to be
\begin{align}
\lambda_1 = \frac{n}{2}(p+q) + 1 \label{eq:lambda1}\\
\lambda_2 = \frac{n}{2}(p-q) + \frac{p+q}{p-q} \label{eq:lambda2}
\end{align}
The corresponding eigenvectors are $w_1$ and $w_2$. The remaining eigen-values are given by the semi-circle law.\\
\\
\textbf{Q10. } Prove that $\lambda_2$ can be separated from the continuous "semi-circle" bulk, to detect the communities  if 
\begin{align}
n(p-q) > \sqrt{2n(p+q)}
\end{align}\\

From \eqref{eq:lambda2} and considering the algebraic relationship (Arithmetic-Mean $\geq$ Geometric-Mean), 
 \begin{align*}
 \lambda_2 &= \frac{1}{2} \bigg(n(p-q) + 2\frac{p+q}{p-q}\bigg) \\
 &= \text{ Arithmetic Mean } \{ n(p-q),  2\frac{p+q}{p-q}\}\\
 &>= \text{ Geometric Mean } \{ n(p-q),  2\frac{p+q}{p-q}\} = \sqrt{2n(p+q)}\\
 \lambda_2 = \frac{1}{2} \bigg(n(p-q) + 2\frac{p+q}{p-q}\bigg) &\geq \sqrt{2n(p+q)}.
 \end{align*}
The above inequality always holds. However, for a strict inequality, we need to consider the following reasoning. 
 
 We note from \eqref{eq:ESD} that for a finite number of eigenvalues to lie within the semi-circle, we require 
 \begin{align}
2n(p+q) - \lambda^2 \geq 0 \implies \lambda \leq \sqrt{2n(p+q)}.
 \end{align}
 Hence, for $\lambda_2$ to lie outside the semi-circle we require
 \begin{align*}
 \lambda &> \sqrt{2n(p+q)}\\
 \lambda_2 = \bigg( \frac{n(p-q)}{2} + \frac{p+q}{p-q} \bigg) &> \sqrt{2n(p+q)}.
 \end{align*}
Consider the relationship for the Arithmetic Mean of two numbers a, b being greater than c:
\begin{align*}
\text{A.M} = \frac{1}{2}(a + b) > c \implies a>c \text{ or } b>c 
\end{align*}
Using this result above, we get
\begin{align*}
 \lambda_2 = \frac{1}{2} \bigg( n(p-q) + 2\frac{p+q}{p-q} \bigg) &> \sqrt{2n(p+q)}\\
 \implies n(p-q) &> \sqrt{2n(p+q)}.
\end{align*}

\textbf{Q11. } Derive the condition for separability of fully connected communities with 
\begin{align}
p = \frac{\alpha}{n} \log(n)\\
q = \frac{\beta}{n} \log(n)
\end{align}\\
With the condition being $n(p-q) > \sqrt{2n(p+q)}$ we substitute the values of p and q to obtain
\begin{align*}
n(p-q) = \log(n)(\alpha - \beta) &> \sqrt{2\log(n)(\alpha + \beta)}\\
(\alpha - \beta) &> \frac{2}{\sqrt{\log(n)}}\sqrt{\frac{(\alpha + \beta)}{2}}
\end{align*}\\

\textbf{Q12. }Derive the condition for separability of non-connected communities with 
\begin{align}
p = \frac{a}{n} \\
q = \frac{b}{n} 
\end{align}\\
With the condition being $n(p-q) > \sqrt{2n(p+q)}$ we substitute the values of p and q to obtain
\begin{align*}
n(p-q) = (a - b) &> \sqrt{2(a + b)}\\
\frac{a-b}{2} &> \sqrt{\frac{a+b}{2}}.
\end{align*}\\


\hrulefill

\section{Experiments}

\subsection{Planted Partition Model}

\textbf{Q 13. Matlab function that takes p,q,n as input and generates the adjacency matrix of the planted partition model. } 

\begin{lstlisting}
function [A, partitionIndicatorVec] = getPartitionGraphModel(n,p,q)
%{ 
Q 13.
n : total #nodes in G
p : probability of link between two vertices inside Cluster
q : probability of link edges between two vertices in opposite clusters
%}

if (mod(n,2) == 0 ) % n is EVEN
%     generate Permutation Matrix, T
    I = eye(n);
    ix = randperm (n);
    T = I(ix,:);

%     generate adjaceny matrix A of a planted partition over n nodes
    n2 = n/2;
    P = random('bino', 1, p, n2, n2); % upper left block
    dP2 = random('bino', 1, p, n2, 1); % diagonal of the lower right block
    Q = random('bino', 1, q, n2, n2); % upper right block
%     carve the two triangular and diagonal matrices that we need
    U = triu(P, 1);
    L = tril(P,-1);
    dP = diag(P);
    B0 = U + U' + diag(dP);
    B1 = Q;
    B2 = Q';
    B3 = L + L' + diag(dP2);
    B =[B0 B1;B2 B3];

    comm1 = ones(1,n2);
    originalCluster = [comm1 -1*comm1];
    

%  PERMUTE THE NODES
%     Re-index Nodes of the graph. 
%     B*T' -> exchg columns; T*M -> exchg rows
    A = T*B*T'; 

%   Obtain the True_Cluster_NodeID for Graph A: Permute them
    partitionIndicatorVec  = originalCluster(ix);
% % -----------------------------------------
else
   warning('n == ODD!') ;
end
end

\end{lstlisting}

\hrulefill



\textbf{Q 14.  Implementation of Partition Algorithm}
\begin{lstlisting}
function partitionIndicatorVec = runPartitionAlgo(A)
%{ 
Algorithm Partition
* compute the second dominant eigenvector, v2, of A, associated with the second largest
eigenvalue ?2.
* for i = 1 to n
if the coordinate i of v2 is positive,(v2)_i > 0, then  %what if its' ZERO?
assign node wi to community 1
else
assign node i to community 2.
end
end

partitionIndicatorVec : = {1(partition A), -1(partition B)}

%}


[V, D] = eigs(A,2);

vec = V(:,2)';
pos = (vec >0);
neg = (vec <0);
partitionIndicatorVec = pos - neg;

end
\end{lstlisting}
\hrulefill


\textbf{Q 15. Computing Overlap between the True-Partition and Predicted/Estimated-Partitions} 

\begin{align}
\omega_i &= \bigg\lbrace \begin{array}{cc}
1 & \text{if i belongs to partition 1}\\
-1 & \text{if i belongs to partition 2}
\end{array} \label{eq:truePartition}\\
\tilde{\omega_i}&= \bigg\lbrace \begin{array}{cc}
1 & \text{if } (v_2)_i > 0,\\
-1 & \text{otherwise}
\end{array} \label{eq:estPartition}\\ 
rawoverlap &= max \bigg( \sum_{i=1}^n  \delta_{\omega_i, \tilde{\omega_i}} ,  \sum_{i=1}^n  \delta_{-\omega_i, \tilde{\omega_i}}   \bigg) \label{eq:rawoverlap}\\
overlap &= \frac{2}{n}rawoverlap - 1 \label{eq:overlap}
\end{align}

(a) Compute overlap score when $\tilde{\omega} = \omega$.\\

From \eqref{eq:rawoverlap} we obtain $rawoverlap = n$ when $\tilde{\omega} = \omega$. Substituting into \eqref{eq:overlap}, we obtain
\begin{align*}
overlap = \frac{2}{n}(n) - 1 = 1
\end{align*}

(b) Prove that a random guess for the detection of the communities returns overlap 0.\\
A random guess for the detection of communities is a Binary vector of $\{-1,1\}^n$ with each component chosen with equal probability $(0.5)$. From the definition \eqref{eq:rawoverlap}, we obtain $rawoverlap = \frac{n}{2}$. Thus, we obtain
\begin{align*}
overlap = \frac{2}{n}\frac{n}{2}  - 1 = 0.
\end{align*}

\begin{lstlisting}
function  overlap = getPartitionOverlap(w1, w2)
%{
Q15. 
Derive the Overlap Metric based on the 
w1 : true partition vector
w2 : estimated partition vector
%}
n = length(w1);
del_w1_w2 = sum(w1 == w2);
del_minus_w1_w2 = sum(-w1 == w2);

rawoverlap = max(del_w1_w2, del_minus_w1_w2);

% random choice of w2 generates a non-zero overlap. Accounting for this:
overlap = (2/n)*rawoverlap - 1;         % Interpret: Prob. of successfully detecting communities.
end

\end{lstlisting}

\hrulefill


\textbf{Q 16/17. Dense and Sparse Communities}


\begin{figure}[h!]
\centering
\includegraphics[scale=0.4]{hw3q16_denseMatrix_final.jpg}\\
\caption{Dense Network: Probability of successfully detecting the partitions using the Partition-Algorithm. The decision boundaries are overlaid in red. The community-recovery algorithm is implemented only for case where $0\leq q<p \leq 1<$. The decision boundary lying inside the Dark region has $(\alpha,\beta)$ values that violate the $q<p$ requirement, and hence, can be ignored. }
\label{fig:DenseNetwork}
\end{figure}




\begin{figure}[h!]
\centering
\includegraphics[scale=0.4]{hw3q16_sparseMatrix.jpg}\\
\caption{Sparse Network: Probability of successfully detecting the partitions using the Partition-Algorithm. The decision boundaries are overlaid in red. The community-recovery algorithm is implemented only for case where $0\leq q<p \leq 1<$. The decision boundary lying inside the Dark region has $(a,b)$ values that violate the $q<p$ requirement, and hence, can be ignored. }
\label{fig:SparseNetwork}
\end{figure}



\begin{lstlisting}
n = 300;
numTrials = 20;
alphaMax = 70;
betaMax = 50;
alphaMin = 5;
betaMin = 1;

Alpha = alphaMin:1:alphaMax;
Beta = betaMin:1:betaMax;

overlapMatrix = zeros(length(Alpha), length(Beta));

for i=1:length(Alpha)
    for j= 1:length(Beta)
        
        alpha = Alpha(i);
        beta = Beta(j);
        
% %         % Dense Matrix
% %         p = alpha/n*log(n);
% %         q = beta/n*log(n);
         
        % Sparse Matrix
        p = alpha/n;
        q = beta/n;
        
        overlapScore = zeros(1,numTrials);
        % ---------------------------------------------------------
        % We need to run the algorithm only if q<p
        % We set the default values to zero!
        if (q<p)
         for iter = 1:numTrials
             [A, w] = getPartitionGraphModel(n,p,q);
             w_pred = runPartitionAlgo(A);
             overlapScore(iter) = getPartitionOverlap(w, w_pred);
         end 
        end
        % ---------------------------------------------------------
         % store the avg. Overlap score for given (alpha,beta)
         overlapMatrix(i,j) = sum(overlapScore)/ numTrials;
    end 
end
% % % 
% % % % ----------------------------------------------------
% % % % Plot the following curve on the 
% % % % alpha - beta > sqrt(0.5*(alpha + beta))*2 / sqrt(log(n))
% % % % k = 2/sqrt(log n)
% % % % alpha > 0.5*( (2*beta + k^2/2)\pm k/2 sqrt(16*beta + k^2/2)   )
% % % 
% % % k = 2/sqrt(log(n));
% % % Alpha1 = 0.5*((2*Beta + k^2/2) + (k/2)*sqrt(16*Beta + k^2));
% % % Alpha2 = 0.5*((2*Beta + k^2/2) - (k/2)*sqrt(16*Beta + k^2));
% % % % ----------------------------------------------------

% ----------------------------------------------------
% How does this change for the sparse matrix?
% SPARSE MATRIX BOUNDARIES
Alpha1 = (Beta + 1) + sqrt(1+ 4*Beta);
Alpha2 = (Beta + 1) - sqrt(1+ 4*Beta);

% ----------------------------------------------------
close all
fig1 = figure(1)
% Plot the image as a GRAYSCALE
betaDim = [betaMin betaMax];
alphaDim = [alphaMin alphaMax];
img = imagesc(betaDim, alphaDim, overlapMatrix);
colormap(gray);
colorbar;
hold on
ax2 = plot(Beta,Alpha1,'r');
% colormap(ax2, parula )
hold on
ax3 = plot(Beta,Alpha2,'r');
% colormap(ax3, parula )
hold off
title('Sparse Matrix: Probability of successfully detecting Partitions')
% title('Dense Matrix: Probability of successfully detecting Partitions')
\end{lstlisting}

\hrulefill



\textbf{Q 18. Zachary's Karate Club}

Overlap Score $= 1$. The code used for implementing the same is described below.
\begin{lstlisting}
load zachary.mat

% From the question/visual graph: Identify true_Partition
nodeIDs = 1:34;
idx_teamA = [25 26 28 32 24 29 30 27 10 34 9 21 33 31 19 23 15 16]
idx_teamB = setdiff(1:34,idx_teamA)

truePartition = ones(size(nodeIDs));
truePartition(idx_teamB) = -1*ones(size(idx_teamB));


% Implement the algorithm to detect the partitions.

M = (A ~= 0 );
adjMatrix = zeros(size(A));
adjMatrix(M) = 1;

estPartition = runPartitionAlgo(adjMatrix);
cluster1 = (estPartition <0);
cluster1_idx_est = cluster1.*nodeIDs;

cluster2 = (estPartition >0);
cluster2_idx_est = cluster2.*nodeIDs;

overlapScore = getPartitionOverlap(truePartition, estPartition)

\end{lstlisting}

\hrulefill

\definition{Planted Partition G(n,p,q)} 
The \emph{Planted Partition G(n,p,q)} is the set of symmetric Adjacency matrices, A representing the network of n nodes
(wlog. n = even). Randomly divide the nodes into equal sets of size n. Each set represents one community.
For any two node pairs in a community, a edge exists between them with probability p. For any two node pairs, with nodes in opposite communities, an edge exists between them with a probability q, such that $0 \leq q <  p \leq 1$. Self-loops can exist in these graphs. Note that the graphs are undirected, and hence require $a_{i,j} = a_{j,i}$.


\end{document}